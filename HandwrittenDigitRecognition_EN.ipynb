{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classification of information using TensorFlow\n",
    "\n",
    "### Recognizing handwritten digits using convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div align=\"right\"><h3>Miroslav Semerád</h3></div>\n",
    "<div align=\"right\"><h4>Miroslav_Semerad@swissre.com</h4></div>\n",
    "<div align=\"right\"><h4>@mldeveloper</h4></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## About this workshop:\n",
    "\n",
    "#### - Introduction to the digit classification problem\n",
    "#### - MNIST - dataset of handwritten digits\n",
    "#### - Simple detection using softmax regression\n",
    "#### - Increasing the accuracy by implementing a convolutional neural network\n",
    "#### - Integration of our model into a web app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Introduction to the digit classification problem\n",
    "\n",
    "- In our business we have a bunch of scanned documents with hand written digits (e.g. dates, amounts, prices).\n",
    "- We want to automatically extract those numbers and use them to categorize our document.\n",
    "- OCR technologies work great for printed text - not so well for handwritten text.\n",
    "- We want to build a simple classifier that will read those numbers from a scan (image).\n",
    "- It is a good introduction to the topic of classification using TensorFlow.\n",
    "\n",
    "![detection](images/detection.png?arg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "### MNIST - dataset of handwritten digits\n",
    "\n",
    "- Available on the Web and free to use.\n",
    "- Contains 60000 images of handwritten digits from 0 to 9.\n",
    "- Images are grayscale (1 color channel) with a resolution of 28 x 28 pixels.\n",
    "- Images are flattened into an array of 784 float numbers - one number per pixel.    \n",
    "- The dataset is split into training (55000) a test (5000) subset.\n",
    "- The dataset is labelled - each image contains the correct label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### An example from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAEWCAYAAABlkpNCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0EiGAABA0P4fgWikprqwcYsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc03902e2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=false; \n",
       "function code_toggle() {\n",
       "    if (code_show){\n",
       "        $('div.cell.code_cell.rendered.selected div.input').hide();\n",
       "    } else {\n",
       "        $('div.cell.code_cell.rendered.selected div.input').show();\n",
       "    }\n",
       "    code_show = !code_show\n",
       "} \n",
       "\n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "\n",
       "<a href=\"javascript:code_toggle()\">Show code</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    example = mnist.test.images[i]\n",
    "    example_label = \"Label: %s\"%[a for a,b in enumerate(mnist.test.labels[i]) if b == 1][0]\n",
    "    plt.title(example_label)\n",
    "    plt.imshow(example.reshape([28,28]), cmap = cm.Greys)\n",
    "    frame1 = plt.gca()\n",
    "    frame1.axes.get_xaxis().set_visible(False)\n",
    "    frame1.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#code hiding\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=false; \n",
    "function code_toggle() {\n",
    "    if (code_show){\n",
    "        $('div.cell.code_cell.rendered.selected div.input').hide();\n",
    "    } else {\n",
    "        $('div.cell.code_cell.rendered.selected div.input').show();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "} \n",
    "\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "\n",
    "<a href=\"javascript:code_toggle()\">Show code</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### How do we use this dataset?\n",
    "\n",
    "We will train our model on this dataset - we'll use the images and the labels.\n",
    "\n",
    "Then we'll use our trained model to classify new data.\n",
    "\n",
    "![training](images/training.png?arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Simple classifier using softmax regression\n",
    "\n",
    "Let's start with a simple regression model to build our first classifier.\n",
    "\n",
    "We will use softmax regression for this task.\n",
    "\n",
    "But first let's import TensorFlow and create a session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TensorFlow InteractiveSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- TensorFlow is a library for numerical calculations developed by the Google Brain team.\n",
    "- Currently it has been open sourced and is one of the most popular projects on Github.\n",
    "- It's build on the data flow graph principle.\n",
    "- All calculation operations are stored in a graph to be executed later.\n",
    "- To execute an operation we have to create a TensorFlow session.\n",
    "- InteractiveSession is an abstraction of the Session - simplyfies the usage of the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "print(\"Version: %s\"%tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Placeholders - entry points to our model\n",
    "\n",
    "To be able to feed the model with external data we need to define our placeholder variables.\n",
    "\n",
    "- **x**  image arrays of 784 elements from the MNIST dataset\n",
    "- **y_** correct labels from the MNIST dataset   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model variables\n",
    "\n",
    "These are local variables of the model. \n",
    "\n",
    "We will not be changing them.\n",
    "\n",
    "The model does change them when it is trained.\n",
    "\n",
    "- **W** - weights - is a matrix of weights, with the dimension of 784 x 10 (pixel x digit)\n",
    "- **b** - bias - population parameter, some digits are less present than others in the dataset. Bias captures these differences and moves the slope to get correct prediction not based on the amounts of a digit in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Variable initialization\n",
    "\n",
    "Befor training we have to initialize our variables to zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Linear model (Score function)\n",
    "\n",
    "We will define the following linear model:\n",
    "\n",
    "### y = x*W + b\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = tf.add(tf.matmul(x,W), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Softmax cost function\n",
    "\n",
    "The cost function calculates the differences between our predicted labels and the real labels from MNIST.\n",
    "\n",
    "The goal is to minimize the cost.\n",
    "\n",
    "Softmax is basically a normalized exponential function.\n",
    "\n",
    "Cross entropy - function to calculate \"unnatural\" probability distribution.\n",
    "\n",
    "- **tf.nn.softmax_cross_entropy_with_logits** - handy function built into TensorFlow\n",
    "- **tf.reduce_mean** - arithmetic mean from all the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "npa = np.array\n",
    "def softmax(w, t = 3.0):\n",
    "    e = np.exp(npa(w) / t)\n",
    "    dist = e / np.sum(e)\n",
    "    return dist\n",
    "\n",
    "arr = np.arange(-10., 10., 0.2)\n",
    "sig = softmax(arr)\n",
    "\n",
    "plt.plot(arr, sig)\n",
    "plt.ylabel('softmax')\n",
    "plt.show()\n",
    "\n",
    "#code hiding\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=false; \n",
    "function code_toggle() {\n",
    "    if (code_show){\n",
    "        $('div.cell.code_cell.rendered.selected div.input').hide();\n",
    "    } else {\n",
    "        $('div.cell.code_cell.rendered.selected div.input').show();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "} \n",
    "\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "\n",
    "<a href=\"javascript:code_toggle()\">Show code</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training of the model\n",
    "\n",
    "The optimizer is an algorithm, that minimizes our cost function by adjusting the Weight (W) and bias (b) variables.\n",
    "\n",
    "Gradient descent - is an iterative algorithm that calculates the steepest descent towards the minimum and then adjusts the values according to the step ratio.\n",
    "\n",
    "- We will use the built-in **GradientDescentOptimizer** with the step size of 0.5.\n",
    "- We will train in batches of 100 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define functions to measure accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# we will store accuracies in a list\n",
    "acc_steps = []\n",
    "\n",
    "# define our train step using the Gradient Descent Optimizer\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# training iterations\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "    if i%10==0:        \n",
    "        acc_steps.append(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "    \n",
    "# visualize accuracy\n",
    "plt.plot(acc_steps)\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy %.f\"%((acc_steps[-1])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    weight = sess.run(W)[:,i]\n",
    "    plt.title(i)\n",
    "    plt.imshow(weight.reshape([28,28]), cmap=plt.get_cmap('seismic'))\n",
    "    frame1 = plt.gca()\n",
    "    frame1.axes.get_xaxis().set_visible(False)\n",
    "    frame1.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "#code hiding\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=false; \n",
    "function code_toggle() {\n",
    "    if (code_show){\n",
    "        $('div.cell.code_cell.rendered.selected div.input').hide();\n",
    "    } else {\n",
    "        $('div.cell.code_cell.rendered.selected div.input').show();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "} \n",
    "\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "\n",
    "<a href=\"javascript:code_toggle()\">Show code</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### How do we increase the accuracy?\n",
    "\n",
    "- The accuracy of ~91% is pretty bad for MNIST.\n",
    "- We can get a lot of bad predictions.\n",
    "- To increase the accuracy we need a more complex model.\n",
    "- A model that is capable to learn more complex patterns from the images.\n",
    "- We will use a ConvNet for this purpose.\n",
    "- But what is a ConvNet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A neural network is a programmatic model, based on the principle of biological neurons.\n",
    "\n",
    "The elemental part is a neuron - a small model with inputs and outputs (synapses).\n",
    "\n",
    "The neuron does our predefinded calculation and passes it to other neurons.\n",
    "\n",
    "ConvNets are a special kind of neural network which mimic the functionality of animal visual cortex.\n",
    "\n",
    "They are based on the principle of convolution, grouping of cetrain neurons that identify certain patterns.\n",
    "\n",
    "ConvNet's perform very well when used for recognizing objects from images or videos.\n",
    "\n",
    "\n",
    "### Our network architecture\n",
    "\n",
    "#### INPUT -> CONV -> RELU -> POOL -> CONV -> RELU -> POOL -> FC -> SOFTMAX -> OUTPUT\n",
    "\n",
    "- CONV - convolutional layer\n",
    "- RELU - activation function\n",
    "- POOL - max pooling - subsampling\n",
    "- FC - fully connected layer\n",
    "- SOFTMAX - softmax regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Helper functions\n",
    "\n",
    "Let's define some helper functions to help us build our convolutional network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### First CONV layer\n",
    "\n",
    "- detects 32 features for each 5x5 patch.\n",
    "- these layers are not densely connected - they are grouped to neighbouring regions\n",
    "\n",
    "Our weights have the dimesion of [5, 5, 1, 32], that is:\n",
    "- width of the patch\n",
    "- height of the patch\n",
    "- number of color channels - in our case inputs\n",
    "- number of output channels - note that we will get a 3D output\n",
    "\n",
    "![conv](images/conv.png?arg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### We will use the ReLU function as our activation function\n",
    "\n",
    "Rectified Linear unit - it's definition is quite simple.\n",
    "\n",
    "Everything below zero becomes zero.\n",
    "\n",
    "### f(x) = max(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "npa = np.array\n",
    "def relu(a):\n",
    "    return a.clip(min=0)\n",
    "\n",
    "arr = np.arange(-10., 10., 0.2)\n",
    "sig = relu(arr)\n",
    "\n",
    "plt.plot(arr, sig)\n",
    "plt.ylabel('ReLU')\n",
    "plt.show()\n",
    "\n",
    "#code hiding\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=false; \n",
    "function code_toggle() {\n",
    "    if (code_show){\n",
    "        $('div.cell.code_cell.rendered.selected div.input').hide();\n",
    "    } else {\n",
    "        $('div.cell.code_cell.rendered.selected div.input').show();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "} \n",
    "\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "\n",
    "<a href=\"javascript:code_toggle()\">Show code</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Max Pooling (subsampling)\n",
    "\n",
    "None linear downsampling.\n",
    "\n",
    "We take each 2x2 patch of the image and pick the highest value.\n",
    "\n",
    "\n",
    "### Changes the resolution form 28x28 to 14x14\n",
    "\n",
    "![pool](images/max_pool.png?arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(tf.add(conv2d(x_image, W_conv1), b_conv1))\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Second CONV layer\n",
    "\n",
    "- Similar to the first one\n",
    "- 5x5 patch\n",
    "- 32 inputs per region\n",
    "- 64 outputs per region\n",
    "\n",
    "### Max Pooling again lowers the resolution to 7x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(tf.add(conv2d(h_pool1, W_conv2), b_conv2))\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully connected layer\n",
    "\n",
    "Standard in most classical neural networks.\n",
    "\n",
    "Connects each neuron from all the regions together.\n",
    "\n",
    "This enables us to detect patterns everywhere on the image not just in the specific region.\n",
    "\n",
    "We'll get 1024 outputs.\n",
    "\n",
    "![fc](images/FCLayer.png?arg)\n",
    "\n",
    "### In the end we will reshape our matrix to a 1D vector with 196 values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.add(tf.matmul(h_pool2_flat, W_fc1), b_fc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Dropout\n",
    "\n",
    "Dropout helps us to reduce overfitting.\n",
    "\n",
    "Overfiting means that our model is too bound to our training data and performs badly on new test data.\n",
    "\n",
    "Dropout is a simple technique of throwing out a random output from a neuron.\n",
    "\n",
    "TensorFlow applies the Dropout automatically based on our specified keep_prob value.\n",
    "\n",
    "We'll use it **only for training!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### SOFTMAX layer\n",
    "\n",
    "Now we will apply our softmax regression to the output of the previous layer to predict the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.add(tf.matmul(h_fc1_drop, W_fc2), b_fc2)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training our model\n",
    "\n",
    "<font color='red'><b>Warning: This could take several minutes on a standard PC.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "acc_steps = []\n",
    "\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%1000 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        acc_steps.append(train_accuracy)\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "\n",
    "# visualize accuracy\n",
    "plt.plot(acc_steps)\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The accuracy is now about **99,2%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Example of classifing another image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "index = 100\n",
    "\n",
    "tmp = mnist.test.images[index]\n",
    "tmp = tmp.reshape((28,28))\n",
    "\n",
    "plt.imshow(tmp, cmap = cm.Greys, interpolation=\"nearest\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Label: %s\"%[a for a,b in enumerate(mnist.test.labels[index]) if b == 1])\n",
    "\n",
    "prediction=tf.argmax(y_conv,1)\n",
    "print(\"Predicted Digit: %s\"%prediction.eval(feed_dict={x: [mnist.test.images[index]], keep_prob: 1.0}, session=sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize the Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def getActivations(activation,example):\n",
    "    units = sess.run(activation,feed_dict={x:[example],keep_prob:1.0})\n",
    "    plotNNFilter(units)\n",
    "\n",
    "def plotNNFilter(units):\n",
    "    filters = units.shape[2]\n",
    "    plt.figure(1, figsize=(20,20))\n",
    "    n_columns = 6\n",
    "    n_rows = math.ceil(filters / n_columns) + 1\n",
    "    for i in range(filters):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Filter ' + str(i))\n",
    "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=plt.get_cmap('coolwarm'))\n",
    "    plt.show()\n",
    "    \n",
    "example_index = index\n",
    "example = mnist.test.images[example_index]\n",
    "example_label = \"'MNIST example: Number %s\"%[a for a,b in enumerate(mnist.test.labels[example_index]) if b == 1][0]\n",
    "\n",
    "#code hiding\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=false; \n",
    "function code_toggle() {\n",
    "    if (code_show){\n",
    "        $('div.cell.code_cell.rendered.selected div.input').hide();\n",
    "    } else {\n",
    "        $('div.cell.code_cell.rendered.selected div.input').show();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "} \n",
    "\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "\n",
    "<a href=\"javascript:code_toggle()\">Show code</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolutional Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "getActivations(h_conv1,example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Max Pooling Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "getActivations(h_pool1,example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolutional Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "getActivations(h_conv2,example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Max Pooling Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "getActivations(h_pool2,example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Saving and restoring the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Saving the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, '/home/s8xcm9/models/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Restoring the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('/home/s8xcm9/models/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Contacts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<h1 style=\"color:blue;\">Miroslav Semerád</h1>\n",
    "<h2>@mldeveloper</h2>\n",
    "<h2>Miroslav_Semerad@swissre.com</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
